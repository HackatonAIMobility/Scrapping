from fastapi import FastAPI, Request
import uvicorn

"""
API Server - Data Ingestion Gateway

Overview:
    This module serves as the critical interface component described in the 
    Scrapping - Data Feeder architecture (api_server.py). It acts as the bridge 
    between the raw data collection layer (scrapers) and the MAI (Mexican 
    Analytics & Insights) intelligence core.

    Its primary purpose is to expose network endpoints that receive scraped data 
    (specifically Metro reports), preprocess it, and forward it to the Large 
    Language Model (LLM) for sentiment analysis and "Customer Happiness Index" 
    calculation.
"""

# ---------------------------------------------------------------------------
# 1. Application Initialization
# 
# What it does: Initializes the FastAPI application instance.
# Aim: To create a lightweight, high-performance web server capable of handling 
# asynchronous requests, which is essential for processing high volumes of 
# incoming social media or news data without blocking the system.
# ---------------------------------------------------------------------------
app = FastAPI()

@app.post("/ingest/metro-data")
async def receive_data(request: Request):
    """
    Data Ingestion Endpoint: /ingest/metro-data

    Aim:
        To serve as the central "door" (entry point) for the data scrapers. 
        It standardizes how external data enters the MAI processing pipeline.

    Inputs (Requirements):
        request (fastapi.Request): The function expects a raw HTTP request object.
        Payload: The body of the request must be a JSON object (typically a list 
        of dictionaries) generated by the scraper modules.
        - Structure: Expected to contain text data (e.g., {'texto': '...', ...}) 
          representing user reports, tweets, or news regarding the Metro system.

    Process & Logic:
        1. Data Extraction: Extracts the JSON payload from the scraper.
        2. Logging: Prints the volume of reports received for monitoring.
        3. LLM Integration Point: Represents the handover point to the MAI 
           Intelligence Layer (ConstraintSatisfactionTracker or sentiment analysis).
        4. Verification: Prints the first record to ensure data integrity.

    Returns:
        JSON Response:
        {
            "status": "exito",
            "mensaje": "Datos recibidos correctamente"
        }
        Significance: Confirms to the scraper that the batch was successfully 
        handed over, allowing the scraper to proceed or finish execution.
    """
    datos = await request.json()
    
    print(f"âš¡ [API] Recibidos {len(datos)} reportes del Metro.")
    
    if datos:
        print(f"   Ejemplo: {datos[0]['texto']}")

    return {"status": "exito", "mensaje": "Datos recibidos correctamente"}

if __name__ == "__main__":
    """
    Server Execution (Main Entry Point)

    What it does: 
        Starts the ASGI server using uvicorn.

    Configuration:
        host="0.0.0.0": This setting is critical for the MAI infrastructure. 
        It binds the server to all available network interfaces, not just localhost.

    Aim: 
        This allows the API to be accessible over a local network (e.g., a Hotspot 
        or a Docker network). This enables a distributed architecture where scrapers 
        running on different machines or containers can successfully push data to 
        this central processing unit.

    Port: 
        Listens on port 8000.
    """
    print("ðŸš€ Servidor escuchando en toda la red local...")
    uvicorn.run(app, host="0.0.0.0", port=8000)